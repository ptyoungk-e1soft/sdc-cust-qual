"""
ë””ìŠ¤í”Œë ˆì´ ê²°í•¨ ë¶„ì„ ì‹œìŠ¤í…œ - ë°ëª¨ ì¸í„°í˜ì´ìŠ¤
Cosmos Reason VLM + GraphRAG ê¸°ë°˜
"""

import gradio as gr
import json
import re
from pathlib import Path
from PIL import Image
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# ìƒ˜í”Œ ì´ë¯¸ì§€ ê²½ë¡œ
SAMPLE_DIR = Path(__file__).parent.parent / "data" / "processed"
SAMPLE_IMAGES = list(SAMPLE_DIR.glob("*.png"))[:10] if SAMPLE_DIR.exists() else []


def parse_model_response(response: str) -> dict:
    """ëª¨ë¸ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ ë°˜í™˜"""
    result = {
        "thinking": "",
        "defect_type": "",
        "location": "",
        "severity": "",
        "cause": "",
        "action": "",
        "raw_response": response,
    }

    # <think> íƒœê·¸ íŒŒì‹±
    think_match = re.search(r"<think>(.*?)</think>", response, re.DOTALL)
    if think_match:
        result["thinking"] = think_match.group(1).strip()

    # <answer> íƒœê·¸ íŒŒì‹±
    answer_match = re.search(r"<answer>(.*?)</answer>", response, re.DOTALL)
    if answer_match:
        answer_text = answer_match.group(1)

        # ê° í•„ë“œ ì¶”ì¶œ
        patterns = {
            "defect_type": r"ê²°í•¨\s*ìœ í˜•[:\s]*([^\n]+)",
            "location": r"ìœ„ì¹˜[:\s]*([^\n]+)",
            "severity": r"ì‹¬ê°ë„[:\s]*([^\n]+)",
            "cause": r"(?:ê°€ëŠ¥í•œ\s*)?ì›ì¸[:\s]*([^\n]+)",
            "action": r"(?:ê¶Œì¥\s*)?ì¡°ì¹˜[:\s]*([^\n]+)",
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, answer_text)
            if match:
                result[key] = match.group(1).strip()

    return result


def get_severity_color(severity: str) -> str:
    """ì‹¬ê°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
    severity_lower = severity.lower()
    if "high" in severity_lower or "ë†’" in severity_lower:
        return "#ff4444"
    elif "medium" in severity_lower or "ì¤‘" in severity_lower:
        return "#ffaa00"
    else:
        return "#44aa44"


def get_severity_emoji(severity: str) -> str:
    """ì‹¬ê°ë„ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    severity_lower = severity.lower()
    if "high" in severity_lower or "ë†’" in severity_lower:
        return "ğŸ”´"
    elif "medium" in severity_lower or "ì¤‘" in severity_lower:
        return "ğŸŸ¡"
    else:
        return "ğŸŸ¢"


def create_result_html(parsed: dict) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ HTMLë¡œ í¬ë§·íŒ…"""
    severity_color = get_severity_color(parsed["severity"])
    severity_emoji = get_severity_emoji(parsed["severity"])

    html = f"""
    <div style="font-family: 'Noto Sans KR', sans-serif; padding: 20px; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; color: white;">

        <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
            <h3 style="margin: 0 0 10px 0; color: #00d4ff;">ğŸ” AI ì¶”ë¡  ê³¼ì •</h3>
            <p style="margin: 0; line-height: 1.6; color: #ccc; font-style: italic;">
                "{parsed['thinking']}"
            </p>
        </div>

        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
            <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;">
                <div style="color: #888; font-size: 12px; margin-bottom: 5px;">ê²°í•¨ ìœ í˜•</div>
                <div style="font-size: 18px; font-weight: bold; color: #fff;">
                    âš ï¸ {parsed['defect_type']}
                </div>
            </div>

            <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;">
                <div style="color: #888; font-size: 12px; margin-bottom: 5px;">ìœ„ì¹˜</div>
                <div style="font-size: 18px; font-weight: bold; color: #fff;">
                    ğŸ“ {parsed['location']}
                </div>
            </div>

            <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;">
                <div style="color: #888; font-size: 12px; margin-bottom: 5px;">ì‹¬ê°ë„</div>
                <div style="font-size: 18px; font-weight: bold; color: {severity_color};">
                    {severity_emoji} {parsed['severity'].upper()}
                </div>
            </div>

            <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px;">
                <div style="color: #888; font-size: 12px; margin-bottom: 5px;">ì¶”ì • ì›ì¸</div>
                <div style="font-size: 16px; color: #fff;">
                    ğŸ”§ {parsed['cause']}
                </div>
            </div>
        </div>

        <div style="background: linear-gradient(90deg, #00d4ff22, #00d4ff11); padding: 15px; border-radius: 10px; margin-top: 15px; border-left: 4px solid #00d4ff;">
            <div style="color: #00d4ff; font-size: 14px; font-weight: bold; margin-bottom: 5px;">
                ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜
            </div>
            <div style="font-size: 16px; color: #fff;">
                {parsed['action']}
            </div>
        </div>
    </div>
    """
    return html


def create_ontology_html(parsed: dict) -> str:
    """GraphRAG ì˜¨í†¨ë¡œì§€ ì‹œê°í™” HTML"""
    html = f"""
    <div style="font-family: 'Noto Sans KR', sans-serif; padding: 20px; background: #0d1117; border-radius: 15px; color: white;">
        <h3 style="color: #58a6ff; margin-bottom: 20px;">ğŸ”— ì§€ì‹ ê·¸ë˜í”„ ì—°ê²°</h3>

        <div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap; gap: 10px;">
            <div style="background: #238636; padding: 10px 20px; border-radius: 20px; font-weight: bold;">
                {parsed['defect_type']}
            </div>
            <div style="color: #58a6ff; font-size: 24px;">â†’</div>
            <div style="background: #1f6feb; padding: 10px 20px; border-radius: 20px;">
                CAUSED_BY
            </div>
            <div style="color: #58a6ff; font-size: 24px;">â†’</div>
            <div style="background: #da3633; padding: 10px 20px; border-radius: 20px; font-weight: bold;">
                {parsed['cause']}
            </div>
        </div>

        <div style="margin-top: 20px; padding: 15px; background: rgba(255,255,255,0.05); border-radius: 10px;">
            <div style="color: #8b949e; font-size: 12px; margin-bottom: 10px;">ê´€ë ¨ ë…¸ë“œ</div>
            <div style="display: flex; gap: 10px; flex-wrap: wrap;">
                <span style="background: #21262d; padding: 5px 15px; border-radius: 15px; font-size: 14px;">ğŸ“ {parsed['location']}</span>
                <span style="background: #21262d; padding: 5px 15px; border-radius: 15px; font-size: 14px;">âš™ï¸ ê³µì • íŒŒë¼ë¯¸í„°</span>
                <span style="background: #21262d; padding: 5px 15px; border-radius: 15px; font-size: 14px;">ğŸ”§ {parsed['action']}</span>
            </div>
        </div>
    </div>
    """
    return html


# ëª¨ë¸ ë¡œë”© ìƒíƒœ
MODEL_LOADED = False
model = None
processor = None


def load_model():
    """ëª¨ë¸ ë¡œë“œ (ì‹¤ì œ GPU í™˜ê²½ì—ì„œë§Œ ë™ì‘)"""
    global MODEL_LOADED, model, processor

    if MODEL_LOADED:
        return True

    try:
        import torch
        from transformers import AutoProcessor
        from peft import PeftModel

        try:
            from transformers import Qwen2_5_VLForConditionalGeneration as VLModel
        except ImportError:
            try:
                from transformers import Qwen2VLForConditionalGeneration as VLModel
            except ImportError:
                from transformers import AutoModelForVision2Seq as VLModel

        print("Loading base model...")
        base_model = VLModel.from_pretrained(
            "nvidia/Cosmos-Reason1-7B",
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True,
        )

        print("Loading LoRA adapter...")
        model = PeftModel.from_pretrained(
            base_model,
            "output/display_defect/checkpoint-200",
            torch_dtype=torch.bfloat16,
        )
        model.eval()

        print("Loading processor...")
        processor = AutoProcessor.from_pretrained(
            "nvidia/Cosmos-Reason1-7B",
            trust_remote_code=True,
        )

        MODEL_LOADED = True
        return True

    except Exception as e:
        print(f"Model loading failed: {e}")
        return False


def analyze_image_real(image):
    """ì‹¤ì œ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„"""
    global model, processor

    if not MODEL_LOADED:
        if not load_model():
            return "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨", "", ""

    import torch

    question = "ì´ ë””ìŠ¤í”Œë ˆì´ íŒ¨ë„ ê²€ì‚¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê²°í•¨ ìœ í˜•ì„ ë¶„ë¥˜í•˜ê³  ê·¼ë³¸ ì›ì¸ì„ ì¶”ë¡ í•´ì£¼ì„¸ìš”."

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": question},
            ],
        }
    ]

    text = processor.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
    )

    try:
        from qwen_vl_utils import process_vision_info
        image_inputs, video_inputs = process_vision_info(messages)
    except:
        image_inputs = [image]
        video_inputs = None

    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        return_tensors="pt",
    )
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
        )

    generated_ids = outputs[0][inputs["input_ids"].shape[1]:]
    response = processor.decode(generated_ids, skip_special_tokens=True)

    parsed = parse_model_response(response)
    result_html = create_result_html(parsed)
    ontology_html = create_ontology_html(parsed)

    return result_html, ontology_html, response


def analyze_image_demo(image):
    """ë°ëª¨ìš© ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ (GPU ì—†ì´ ë™ì‘)"""
    import random

    defect_types = ["ë¼ì¸ ê²°í•¨", "íœ˜ì  ê²°í•¨", "ë°ë“œ í”½ì…€", "ë¬´ë¼ (ë¶ˆê· ì¼)", "ìŠ¤í¬ë˜ì¹˜", "ì´ë¬¼ì§ˆ"]
    locations = ["ì¢Œì¸¡ ìƒë‹¨", "ì¤‘ì•™ë¶€", "ìš°ì¸¡ í•˜ë‹¨", "ì¤‘ì•™ ìƒë‹¨", "ì¢Œì¸¡ í•˜ë‹¨"]
    severities = ["high", "medium", "low"]
    causes = [
        "ì „ê·¹ í„°ì¹˜ íŒ¨í„´ê³¼ì˜ ìƒí˜¸ì‘ìš©",
        "ë°±ë¼ì´íŠ¸ ë¶ˆê· ì¼",
        "TFT êµ¬ë™ íšŒë¡œ ê²°í•¨",
        "ì „í•˜ ëˆ„ì ",
        "ì¹˜êµ¬ ì ‘ì´‰",
        "í´ë¦°ë£¸ í™˜ê²½ ì˜¤ì—¼",
    ]
    actions = [
        "ê· ì¼í•œ ì „ê·¹ íŒ¨í„´ í™•ì¸",
        "ë°±ë¼ì´íŠ¸ ì¡°ì •",
        "TFT ê²€ì‚¬ ê°•í™”",
        "ì ˆì—° ê³µì • íŒŒë¼ë¯¸í„° ì¡°ì •",
        "ë³´í˜¸ í•„ë¦„ ì ìš©",
        "í´ë¦°ë£¸ ì²­ì •ë„ ì ê²€",
    ]

    idx = random.randint(0, len(defect_types) - 1)

    parsed = {
        "thinking": f"ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•œ ê²°ê³¼, {random.choice(locations)} ì˜ì—­ì—ì„œ {defect_types[idx]} íŒ¨í„´ì´ ê´€ì°°ë©ë‹ˆë‹¤. ê²°í•¨ì˜ í˜•íƒœì™€ ë¶„í¬ë¥¼ ê³ ë ¤í•  ë•Œ, {causes[idx]}ì´ ì›ì¸ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.",
        "defect_type": defect_types[idx],
        "location": random.choice(locations),
        "severity": random.choice(severities),
        "cause": causes[idx],
        "action": actions[idx],
    }

    raw_response = f"""<think>{parsed['thinking']}</think>
<answer>
ê²°í•¨ ìœ í˜•: {parsed['defect_type']}
ìœ„ì¹˜: {parsed['location']}
ì‹¬ê°ë„: {parsed['severity']}
ê°€ëŠ¥í•œ ì›ì¸: {parsed['cause']}
ê¶Œì¥ ì¡°ì¹˜: {parsed['action']}
</answer>"""

    result_html = create_result_html(parsed)
    ontology_html = create_ontology_html(parsed)

    return result_html, ontology_html, raw_response


def analyze_image(image, use_real_model: bool = False):
    """ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
    if image is None:
        return (
            "<div style='padding: 20px; text-align: center; color: #666;'>ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.</div>",
            "",
            "",
        )

    if use_real_model:
        return analyze_image_real(image)
    else:
        return analyze_image_demo(image)


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
def create_demo():
    with gr.Blocks(
        title="ë””ìŠ¤í”Œë ˆì´ ê²°í•¨ ë¶„ì„ ì‹œìŠ¤í…œ",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="cyan",
        ),
        css="""
        .gradio-container {
            max-width: 1400px !important;
        }
        .header {
            text-align: center;
            padding: 20px;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            border-radius: 15px;
            margin-bottom: 20px;
        }
        .header h1 {
            color: #00d4ff;
            margin: 0;
        }
        .header p {
            color: #888;
            margin: 10px 0 0 0;
        }
        """,
    ) as demo:

        # í—¤ë”
        gr.HTML("""
        <div class="header">
            <h1>ğŸ–¥ï¸ ë””ìŠ¤í”Œë ˆì´ ê²°í•¨ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
            <p>Cosmos Reason VLM + GraphRAG ê¸°ë°˜ ì§€ëŠ¥í˜• í’ˆì§ˆ ê²€ì‚¬</p>
        </div>
        """)

        with gr.Row():
            # ì™¼ìª½: ì´ë¯¸ì§€ ì…ë ¥
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ ì´ë¯¸ì§€ ì…ë ¥")
                image_input = gr.Image(
                    type="pil",
                    label="ê²€ì‚¬ ì´ë¯¸ì§€",
                    height=400,
                )

                with gr.Row():
                    use_real = gr.Checkbox(
                        label="ì‹¤ì œ ëª¨ë¸ ì‚¬ìš© (GPU í•„ìš”)",
                        value=False,
                    )
                    analyze_btn = gr.Button(
                        "ğŸ” ë¶„ì„ ì‹œì‘",
                        variant="primary",
                        size="lg",
                    )

                # ìƒ˜í”Œ ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬
                if SAMPLE_IMAGES:
                    gr.Markdown("#### ìƒ˜í”Œ ì´ë¯¸ì§€")
                    sample_gallery = gr.Gallery(
                        value=[(str(img), img.name) for img in SAMPLE_IMAGES[:6]],
                        columns=3,
                        height=150,
                        label="í´ë¦­í•˜ì—¬ ì„ íƒ",
                    )

            # ì˜¤ë¥¸ìª½: ë¶„ì„ ê²°ê³¼
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
                result_output = gr.HTML(
                    label="ë¶„ì„ ê²°ê³¼",
                )

                gr.Markdown("### ğŸ”— GraphRAG ì˜¨í†¨ë¡œì§€")
                ontology_output = gr.HTML(
                    label="ì˜¨í†¨ë¡œì§€",
                )

        # Raw ì‘ë‹µ (ì ‘ê¸° ê°€ëŠ¥)
        with gr.Accordion("ğŸ”§ Raw ëª¨ë¸ ì‘ë‹µ", open=False):
            raw_output = gr.Textbox(
                label="ì›ë³¸ ì‘ë‹µ",
                lines=10,
            )

        # ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ëª…
        with gr.Accordion("ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", open=False):
            gr.Markdown("""
            ## ì‹œìŠ¤í…œ êµ¬ì„±

            ```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                    ë””ìŠ¤í”Œë ˆì´ ê²°í•¨ ë¶„ì„ ì‹œìŠ¤í…œ                      â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚                                                                  â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
            â”‚  â”‚   ì´ë¯¸ì§€     â”‚ -> â”‚  VLM ì¶”ë¡     â”‚ -> â”‚  ê²°ê³¼ íŒŒì‹±    â”‚       â”‚
            â”‚  â”‚   ì…ë ¥       â”‚    â”‚  (7B ëª¨ë¸)   â”‚    â”‚  & ì‹œê°í™”    â”‚       â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
            â”‚                            â”‚                                     â”‚
            â”‚                            â–¼                                     â”‚
            â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
            â”‚                    â”‚  GraphRAG    â”‚                             â”‚
            â”‚                    â”‚  ì˜¨í†¨ë¡œì§€     â”‚                             â”‚
            â”‚                    â”‚  (Neo4j)     â”‚                             â”‚
            â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
            â”‚                            â”‚                                     â”‚
            â”‚                            â–¼                                     â”‚
            â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
            â”‚                    â”‚  ê·¼ë³¸ì›ì¸     â”‚                             â”‚
            â”‚                    â”‚  ì¶”ë¡  ì—”ì§„    â”‚                             â”‚
            â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            ```

            ### í•µì‹¬ ê¸°ìˆ 

            | êµ¬ì„±ìš”ì†Œ | ê¸°ìˆ  | ì„¤ëª… |
            |---------|------|------|
            | **VLM** | Cosmos Reason 7B | NVIDIAì˜ ì¶”ë¡  íŠ¹í™” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ |
            | **Fine-tuning** | LoRA (r=64) | ê²½ëŸ‰í™”ëœ íŒŒì¸íŠœë‹ìœ¼ë¡œ ë„ë©”ì¸ íŠ¹í™” |
            | **GraphRAG** | Neo4j | ê²°í•¨-ì›ì¸-ê³µì • ê´€ê³„ ê·¸ë˜í”„ |
            | **API** | FastAPI | RESTful API ì„œë²„ |
            | **ë°°í¬** | Docker + GPU | ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬ |
            """)

        # ì´ë²¤íŠ¸ ì—°ê²°
        analyze_btn.click(
            fn=analyze_image,
            inputs=[image_input, use_real],
            outputs=[result_output, ontology_output, raw_output],
        )

        # ê°¤ëŸ¬ë¦¬ì—ì„œ ì´ë¯¸ì§€ ì„ íƒ ì‹œ
        if SAMPLE_IMAGES:
            def load_sample(evt: gr.SelectData):
                return Image.open(SAMPLE_IMAGES[evt.index])

            sample_gallery.select(
                fn=load_sample,
                outputs=image_input,
            )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )
